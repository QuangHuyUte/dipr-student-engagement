import streamlit as st
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import tempfile
import os
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="AI Gi√°m S√°t L·ªõp H·ªçc",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS T√ôY CH·ªàNH CHO GIAO DI·ªÜN ƒê·∫∏P ---
st.markdown("""
    <style>
    .main { background-color: #f5f5f5; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #4CAF50; color: white; }
    .metric-card { background-color: white; padding: 15px; border-radius: 10px; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); text-align: center; }
    .alert-box { padding: 10px; border-radius: 5px; color: white; margin-bottom: 10px; }
    .high-score { background-color: #28a745; }
    .low-score { background-color: #dc3545; }
    </style>
    """, unsafe_allow_html=True)

# --- KHAI B√ÅO NH√ÉN & M√ÄU S·∫ÆC ---
CLASS_NAMES = {
    0: 'listening', 1: 'looking_away', 2: 'sleeping', 
    3: 'using_laptop', 4: 'using_phone', 5: 'writing'
}

# Nh√≥m h√†nh vi: T√≠ch c·ª±c (Positive) & Ti√™u c·ª±c (Negative)
POSITIVE_ACTIONS = ['listening', 'writing', 'using_laptop']
NEGATIVE_ACTIONS = ['sleeping', 'using_phone', 'looking_away']

# M√†u s·∫Øc cho Bounding Box
COLORS = {
    'listening': (0, 255, 0), 'writing': (0, 200, 255), 'using_laptop': (0, 255, 255), # Xanh
    'sleeping': (0, 0, 255), 'using_phone': (0, 0, 150), 'looking_away': (0, 100, 255) # ƒê·ªè/Cam
}

# --- H√ÄM LOAD MODEL ---
@st.cache_resource
def load_model(model_path):
    return YOLO(model_path)

# --- H√ÄM T√çNH TO√ÅN CH·ªà S·ªê ---
def calculate_metrics(detections):
    counts = {name: 0 for name in CLASS_NAMES.values()}
    total_students = len(detections)
    
    if total_students == 0:
        return counts, 0, 0

    for cls_id in detections:
        label = CLASS_NAMES[int(cls_id)]
        counts[label] += 1
    
    positive_count = sum(counts[act] for act in POSITIVE_ACTIONS)
    engagement_score = (positive_count / total_students) * 100
    
    return counts, total_students, round(engagement_score, 2)

# --- SIDEBAR ---
with st.sidebar:
    st.title("‚öôÔ∏è C·∫•u h√¨nh H·ªá th·ªëng")
    st.image("https://cdn-icons-png.flaticon.com/512/3069/3069172.png", width=100)
    
    # Upload Model n·∫øu ch∆∞a c√≥ trong folder
    model_file = "models/best.pt"
    if not os.path.exists(model_file):
        st.warning("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y file models/best.pt")
        uploaded_model = st.file_uploader("Upload file model (.pt)", type=['pt'])
        if uploaded_model:
            with open(model_file, "wb") as f:
                f.write(uploaded_model.getbuffer())
            st.success("ƒê√£ t·∫£i model l√™n!")
            st.rerun()
    
    conf_threshold = st.slider("ƒê·ªô tin c·∫≠y (Confidence)", 0.0, 1.0, 0.4)
    alert_threshold = st.slider("Ng∆∞·ª°ng c·∫£nh b√°o t·∫≠p trung (%)", 0, 100, 60)
    st.markdown("---")
    st.info("üí° **H·ªá th·ªëng ph√¢n t√≠ch:**\n- **T√≠ch c·ª±c:** Listening, Writing, Laptop\n- **Ti√™u c·ª±c:** Phone, Sleeping, Looking Away")

# --- MAIN APP ---
if os.path.exists(model_file):
    model = load_model(model_file)
    
    st.title("üéì H·ªá Th·ªëng Ph√¢n T√≠ch M·ª©c ƒê·ªô T·∫≠p Trung L·ªõp H·ªçc")
    
    tab1, tab2 = st.tabs(["üñºÔ∏è Ph√¢n T√≠ch ·∫¢nh", "üé• Ph√¢n T√≠ch Video"])

    # ================= TAB 1: X·ª¨ L√ù ·∫¢NH =================
    with tab1:
        st.header("Upload ·∫¢nh L·ªõp H·ªçc")
        img_file = st.file_uploader("Ch·ªçn ·∫£nh (.jpg, .png)", type=['jpg', 'png', 'jpeg'])
        
        if img_file:
            # ƒê·ªçc ·∫£nh
            file_bytes = np.asarray(bytearray(img_file.read()), dtype=np.uint8)
            img = cv2.imdecode(file_bytes, 1)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # X·ª≠ l√Ω AI
            results = model.predict(img, conf=conf_threshold)
            detections = results[0].boxes.cls.cpu().numpy()
            
            # T√≠nh to√°n
            counts, total, score = calculate_metrics(detections)
            
            # V·∫Ω Bounding Box
            for result in results:
                res_plotted = result.plot()
                res_plotted = cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB)

            # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
            col_img, col_stat = st.columns([2, 1])
            
            with col_img:
                st.image(res_plotted, caption="K·∫øt qu·∫£ nh·∫≠n di·ªán", use_column_width=True)
            
            with col_stat:
                st.subheader("üìä Th·ªëng K√™")
                
                # Hi·ªÉn th·ªã ƒëi·ªÉm s·ªë l·ªõn
                color_class = "high-score" if score >= alert_threshold else "low-score"
                st.markdown(f"""
                <div class="alert-box {color_class}" style="text-align: center;">
                    <h2>{score}%</h2>
                    <p>M·ª®C ƒê·ªò T·∫¨P TRUNG</p>
                </div>
                """, unsafe_allow_html=True)
                
                st.metric("T·ªïng s·ªë sinh vi√™n", f"{total} ng∆∞·ªùi")
                
                # Bi·ªÉu ƒë·ªì tr√≤n
                df_counts = pd.DataFrame(list(counts.items()), columns=['H√†nh vi', 'S·ªë l∆∞·ª£ng'])
                fig = px.pie(df_counts, values='S·ªë l∆∞·ª£ng', names='H√†nh vi', hole=0.4, 
                             color='H√†nh vi',
                             color_discrete_map={'listening':'green', 'sleeping':'red', 'using_phone':'darkred'})
                st.plotly_chart(fig, use_container_width=True)
                
                # N√∫t xu·∫•t b√°o c√°o
                csv = df_counts.to_csv(index=False).encode('utf-8')
                st.download_button("üì• Xu·∫•t b√°o c√°o CSV", data=csv, file_name="report_image.csv", mime="text/csv")

    # ================= TAB 2: X·ª¨ L√ù VIDEO =================
    with tab2:
        st.header("Upload Video Gi√°m S√°t")
        video_file = st.file_uploader("Ch·ªçn video (.mp4, .avi)", type=['mp4', 'avi', 'mov'])
        
        if video_file:
            tfile = tempfile.NamedTemporaryFile(delete=False)
            tfile.write(video_file.read())
            video_path = tfile.name
            
            col_vid_left, col_vid_right = st.columns([3, 1])
            
            with col_vid_left:
                start_btn = st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch Video")
            
            if start_btn:
                cap = cv2.VideoCapture(video_path)
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                
                # Thanh ti·∫øn tr√¨nh & Placeholder hi·ªÉn th·ªã video
                progress_bar = st.progress(0)
                status_text = st.empty()
                frame_placeholder = st.empty()
                
                # D·ªØ li·ªáu theo th·ªùi gian
                timeline_data = []
                frame_idx = 0
                
                # T·∫°o file output t·∫°m
                temp_output = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                output_path = temp_output.name
                
                # Codec cho video output (D√πng mp4v cho t∆∞∆°ng th√≠ch c∆° b·∫£n)
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
                
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    # AI Predict
                    results = model.predict(frame, conf=conf_threshold, verbose=False)
                    detections = results[0].boxes.cls.cpu().numpy()
                    
                    # T√≠nh to√°n ch·ªâ s·ªë cho frame n√†y
                    _, _, score = calculate_metrics(detections)
                    
                    # L∆∞u d·ªØ li·ªáu timeline
                    timestamp = round(frame_idx / fps, 2)
                    timeline_data.append({
                        "Time (s)": timestamp,
                        "Engagement (%)": score,
                        "Status": "Low" if score < alert_threshold else "High"
                    })
                    
                    # V·∫Ω l√™n frame
                    annotated_frame = results[0].plot()
                    
                    # Hi·ªÉn th·ªã th√¥ng s·ªë tr·ª±c ti·∫øp l√™n video
                    color = (0, 255, 0) if score >= alert_threshold else (0, 0, 255)
                    cv2.putText(annotated_frame, f"Engagement: {score}%", (50, 50), 
                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)
                    
                    out.write(annotated_frame)
                    
                    # C·∫≠p nh·∫≠t giao di·ªán (m·ªói 5 frame update 1 l·∫ßn cho nh·∫π)
                    if frame_idx % 5 == 0:
                        frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                        frame_placeholder.image(frame_rgb, channels="RGB", caption=f"ƒêang x·ª≠ l√Ω: {timestamp}s")
                        progress = frame_idx / total_frames
                        progress_bar.progress(progress)
                        status_text.text(f"‚è≥ ƒêang x·ª≠ l√Ω... {int(progress*100)}%")
                    
                    frame_idx += 1
                
                cap.release()
                out.release()
                progress_bar.progress(100)
                status_text.success("‚úÖ ƒê√£ x·ª≠ l√Ω xong!")
                frame_placeholder.empty() # X√≥a ·∫£nh preview ƒë·ªÉ hi·ªán video final

                # --- X·ª¨ L√ù K·∫æT QU·∫¢ VIDEO ---
                st.divider()
                
                # 1. BI·ªÇU ƒê·ªí DI·ªÑN BI·∫æN (Tua ƒë∆∞·ª£c b·∫±ng m·∫Øt)
                df_timeline = pd.DataFrame(timeline_data)
                
                # T·∫°o bi·ªÉu ƒë·ªì v√πng (Area Chart) v·ªõi Plotly
                fig_timeline = px.area(df_timeline, x='Time (s)', y='Engagement (%)', 
                                       title="üìà Bi·ªÉu ƒë·ªì M·ª©c ƒë·ªô t·∫≠p trung theo th·ªùi gian",
                                       color='Status',
                                       color_discrete_map={'High': '#28a745', 'Low': '#dc3545'})
                
                # Th√™m ƒë∆∞·ªùng k·∫ª ngang m·ª©c b√°o ƒë·ªông
                fig_timeline.add_hline(y=alert_threshold, line_dash="dash", line_color="red", 
                                       annotation_text=f"Ng∆∞·ª°ng {alert_threshold}%")
                
                # ƒê√°nh d·∫•u c√°c kho·∫£ng th·ªùi gian nguy hi·ªÉm
                low_eng = df_timeline[df_timeline['Engagement (%)'] < alert_threshold]
                if not low_eng.empty:
                    st.error(f"‚ö†Ô∏è C·∫¢NH B√ÅO: L·ªõp h·ªçc m·∫•t t·∫≠p trung trong {len(low_eng)/fps:.1f} gi√¢y (C√°c v·∫°ch m√†u ƒë·ªè tr√™n bi·ªÉu ƒë·ªì).")
                
                st.plotly_chart(fig_timeline, use_container_width=True)

                # 2. XEM VIDEO & T·∫¢I V·ªÄ
                col_result_video, col_result_stat = st.columns([2, 1])
                
                with col_result_video:
                    st.subheader("üé• Video K·∫øt Qu·∫£")
                    # L∆∞u √Ω: ƒê·ªÉ video mp4 play ƒë∆∞·ª£c tr√™n web, c·∫ßn convert sang h264. 
                    # V√¨ ta d√πng opencv thu·∫ßn n√™n ta s·∫Ω cho user download file ƒë·ªÉ xem chu·∫©n nh·∫•t 
                    # ho·∫∑c c·ªë g·∫Øng hi·ªÉn th·ªã (c√≥ th·ªÉ l·ªói codec t√πy tr√¨nh duy·ªát)
                    st.video(output_path)
                    
                    with open(output_path, 'rb') as f:
                        st.download_button("‚¨áÔ∏è T·∫£i Video ƒë√£ ph√¢n t√≠ch", f, file_name="processed_video.mp4")
                        
                with col_result_stat:
                    st.subheader("üìë T·ªïng k·∫øt Video")
                    avg_score = df_timeline['Engagement (%)'].mean()
                    min_score = df_timeline['Engagement (%)'].min()
                    
                    st.metric("T·∫≠p trung trung b√¨nh", f"{avg_score:.1f}%")
                    st.metric("T·∫≠p trung th·∫•p nh·∫•t", f"{min_score:.1f}%", delta_color="inverse")
                    
                    # Xu·∫•t b√°o c√°o chi ti·∫øt
                    csv_video = df_timeline.to_csv(index=False).encode('utf-8')
                    st.download_button("üì• T·∫£i B√°o c√°o chi ti·∫øt (CSV)", csv_video, 
                                       file_name="video_analytics.csv", mime="text/csv")
else:
    st.warning("Vui l√≤ng t·∫£i file model best.pt v√†o th∆∞ m·ª•c 'models' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")